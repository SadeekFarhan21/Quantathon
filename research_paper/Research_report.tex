% !TEX program = xelatex
\documentclass[10pt]{article}

\usepackage{libertine}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{booktabs}
%\usepackage{fontspec}
\usepackage[colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black]{hyperref}

\geometry{
    margin=1in,
    headheight=12pt
}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{\small 2025 Ohio State Quantathon}
\fancyhead[R]{\small\thepage}
\fancyfoot[C]{\small Extended Abstract}

\titleformat{\section}
    {\normalfont\large\bfseries}{\thesection}{1em}{}
\titlespacing*{\section}
    {0pt}{2.5ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand{\maketitle}{%
    \begin{center}
        \vspace*{0.5cm}
        \Large\@title
        
        \vspace{0.4cm}
        \large\@author
        
        \vspace{0.5cm}
        \normalsize\textit{Quantathon 2025}
        
        \vspace{0.3cm}
        \normalsize Extended Abstract
        \vspace{0.5cm}
    \end{center}
}
\makeatother
% Color
\usepackage{amsmath} % for aligned
\usepackage{listofitems} % for \readlist to create arrays
\usepackage{tikz} % Required for TikZ functionality
\usetikzlibrary{arrows.meta} % for arrow size
\usepackage[outline]{contour} % glow around text
\contourlength{1.4pt}

\usepackage{xcolor}
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}
\usetikzlibrary{positioning}

\def\layersep{2}
\def\nodesep{1.5}
% STYLES
\tikzset{
  >=latex, % for default LaTeX arrow head
  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},
  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},
  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},
  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},
  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},
  connect/.style={thick,mydarkblue}, %,line cap=round
  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1},
  node 1/.style={node in}, % node styles, numbered for easy mapping with \nstyle
  node 2/.style={node hidden},
  node 3/.style={node out}
}
\def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3


% Paper info
\title{Predicting Market States and Optimizing Investment Strategies: \\
A Machine Learning Approach}
\author{Jalen Francis, Aditya Bhati, Farhan Sadeek, Jayson Clark, and Andrew McKenzie}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
	This research presents a comprehensive quantitative system for predicting market states and optimizing investment strategies. Using S\&P 500 data from 2008-2022, the system classifies market periods as Bull, Bear, or Static based on drawdown metrics, then employs ensemble machine learning and deep learning models to predict future market conditions. The prediction results are used to implement multiple investment strategies that dynamically allocate between equities and bonds. Additionally, the system incorporates advanced anomaly detection for early warning of market disruptions, yield curve analysis for macroeconomic insights, and catastrophe modeling for tail risk analysis. Our Combined Anomaly-Regime strategy achieved a 56.34\% total return versus 52.97\% for buy-and-hold, with significantly better risk-adjusted performance (Sharpe ratio 1.09 vs 0.58) and reduced maximum drawdown (-10.28\% vs -33.92\%). These results demonstrate that sophisticated machine learning techniques can effectively enhance investment decision-making and risk management in financial markets.
\end{abstract}

\section{Introduction and Problem Statement}
Financial market prediction has long been a challenging domain, with the Efficient Market Hypothesis suggesting that accurate prediction is impossible in liquid markets. Yet, empirical evidence shows patterns in aggregate market behavior, particularly during extreme market conditions. Our research investigates whether machine learning techniques can effectively predict market states and generate superior investment strategies.

The core problems we address are:
\begin{itemize}
	\item How to objectively classify market states using quantitative metrics
	\item Whether machine learning models can predict transitions between market states
	\item How to translate predictions into effective investment strategies
	\item How to detect and respond to market anomalies and extreme events
\end{itemize}

This research applies a quantitative approach to develop a comprehensive system for market prediction and portfolio management, with an emphasis on risk-adjusted performance.

\section{Data and Methodology}
\subsection{Data Sources}
The primary data for this study consists of:
\begin{itemize}
	\item S\&P 500 daily price data (2008-2022)
	\item 10-year Treasury bond yields
	\item Market-based probability indicators (PrDec and PrInc)
\end{itemize}

We divided the data chronologically, using earlier periods (2008-2018) for model training and later periods (2019-2022) for out-of-sample testing and strategy validation.

\subsection{Research Framework}
Our methodology follows a systematic pipeline:
\begin{enumerate}
	\item Market state classification using drawdown analysis
	\item Feature engineering from price and probability data
	\item Model development and training (traditional ML and deep learning)
	\item Anomaly detection and risk analysis
	\item Strategy development and backtesting
	\item Performance evaluation and optimization
\end{enumerate}

The implemented system operates in a forward-testing manner, making predictions and investment decisions using only data available at each decision point, avoiding look-ahead bias.

\section{Market State Classification}
We classified market states using drawdown from peak methodology, which is widely accepted in financial literature:
\begin{itemize}
	\item \textbf{Bear Market}: Period with drawdown exceeding 20\% from the previous peak
	\item \textbf{Bull Market}: Period with price increasing above the last bear market trough
	\item \textbf{Static Market}: Transitional periods between clear bull and bear regimes
\end{itemize}
Using this methodology, we identified several distinct market regimes in our dataset, including the 2008 Financial Crisis, the 2018 Q4 correction, and the 2020 COVID-19 crash. The classification algorithm was implemented via a custom MarketClassifier class that accurately tracks market states with 95% accuracy and labels market periods accordingly. This high accuracy demonstrates the effectiveness of our drawdown-based approach in identifying market regimes.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{../results/market_states.png}
	\caption{Market State Classification with Drawdown Analysis}
	\label{fig:market_states}
\end{figure}


\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{../results/confusion_matrix.png}
	\caption{Confusion Matrix for Market State Detector}
	\label{fig:confusion_matrix}
\end{figure}

Our analysis found that bear markets occurred approximately 18\% of the time, bull markets 65\%, and static markets 17\%. These percentages are consistent with historical market behavior literature, validating our classification approach.



\section{Advanced Prediction Models}
\subsection{Feature Engineering}
We engineered features from raw market data to capture various market dynamics:
\begin{itemize}
	\item Price-based features: Moving averages, momentum indicators, volatility measures
	\item Probability indicators: Direct use and derived features from PrDec and PrInc
	\item Relationship features: Ratios between different indicators
	\item Technical indicators: RSI, MACD, and other established metrics
\end{itemize}

Feature importance analysis revealed that the most predictive features were:
\begin{enumerate}
	\item Short-term trend consistency (20\% contribution)
	\item Probability indicator divergence (15\% contribution)
	\item Market volatility patterns (12\% contribution)
	\item Price/fundamentals relationship indicators (10\% contribution)
\end{enumerate}

\subsection{Model Development}

We implemented and compared several predictive model architectures:

\subsubsection{Traditional Machine Learning Models}
\begin{itemize}
	\item Random Forest Classifier with optimized hyperparameters
	\item Gradient Boosting with regularization to prevent overfitting
	\item Support Vector Machines with kernel optimization
\end{itemize}

\subsubsection{Advanced Deep Learning Models}
We developed custom deep learning architectures to capture complex temporal patterns:
\begin{itemize}
	\item \textbf{Attention-based LSTM}: A bidirectional LSTM with self-attention mechanisms to focus on the most relevant time points in market sequence data. The attention mechanism improved model performance by 14\% compared to standard LSTM.

	\item \textbf{Temporal Convolutional Network (TCN)}: A specialized 1D convolutional architecture that processes market data across different time scales simultaneously, capturing multi-timeframe patterns.

	\item \textbf{Ensemble Framework}: Combined multiple model types using a weighted averaging approach, significantly reducing prediction variance and improving robustness to market regime shifts.
\end{itemize}

\begin{center}
	\begin{tikzpicture}[x=2.2cm,y=1.4cm]
		\message{^^JNeural network with arrows}
		\readlist\Nnod{4,5,5,5,3} % array of number of nodes per layer

		\message{^^J  Layer}
		\foreachitem \N \in \Nnod{ % loop over layers
			\edef\lay{\Ncnt} % alias of index of current layer
			\message{\lay,}
			\pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
			\foreach \i [evaluate={\y=\N/2-\i; \x=\lay; \n=\nstyle;}] in {1,...,\N}{ % loop over nodes

					% NODES
					\node[node \n] (N\lay-\i) at (\x,\y) {$a_\i^{(\prev)}$};
					%\node[circle,inner sep=2] (N\lay-\i') at (\x-0.15,\y) {}; % shifted node
					%\draw[node] (N\lay-\i) circle (\R);

					% CONNECTIONS
					\ifnum\lay>1 % connect to previous layer
						\foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
								\draw[connect arrow] (N\prev-\j) -- (N\lay-\i); % connect arrows directly
								%\draw[connect arrow] (N\prev-\j) -- (N\lay-\i'); % connect arrows to shifted node
							}
					\fi % else: nothing to connect first layer

				}

		}
	\end{tikzpicture}
\end{center}

To prevent overfitting, we implemented:
\begin{itemize}
	\item Early stopping with patience parameters
	\item Dropout regularization (0.4 rate in hidden layers)
	\item Batch normalization
	\item Data augmentation techniques
\end{itemize}


\begin{center}
	\begin{tikzpicture}[
			node/.style={circle, draw, thick},
		]

		\foreach \y in {1,...,5}{
				\node[node] (i\y) at (0,\nodesep*\y) {};
				\node[node, right=\layersep of i\y] (h1\y) {};
				\node[node, right=\layersep of h1\y] (h2\y) {};
			}

		\node[node, right=\layersep of h22] (o1) {};
		\node[node, right=\layersep of h24] (o2) {};

		\foreach \source in {1,...,5}
		\foreach \dest in {1,...,5}{
				\path[-stealth, thick] (i\source) edge (h1\dest);
				\path[-stealth, thick] (h1\source) edge (h2\dest);
			}
		\foreach \source in {1,...,5}
		\foreach \dest in {1,2}
		\draw[-stealth, thick] (h2\source) -- (o\dest);

		\draw[-stealth, thick] (7.5,3*\nodesep) -- node[above,font=\Large\bfseries] {dropout} (9.5, 3*\nodesep);

		% Boundary

		\foreach \y in {1,...,5}
		\node[node, right=15em of h2\y] (di\y) {};

		\node[red,font=\huge] at (di1) {$\times$};
		\node[red,font=\huge] at (di3) {$\times$};

		\foreach \y in {1,...,5}
		\node[node, right=\layersep of di\y] (dh1\y) {};

		\node[red,font=\huge] at (dh11) {$\times$};
		\node[red,font=\huge] at (dh14) {$\times$};

		\foreach \y in {1,...,5}
		\node[node, right=\layersep of dh1\y] (dh2\y) {};

		\node[red,font=\huge] at (dh22) {$\times$};
		\node[red,font=\huge] at (dh24) {$\times$};

		\node[node, right=\layersep of dh22] (do1) {};
		\node[node, right=\layersep of dh24] (do2) {};

		\foreach \source in {2,4,5}
		\foreach \dest in {2,3,5}
		\draw[-stealth, thick] (di\source) -- (dh1\dest);

		\foreach \source in {2,3,5}
		\foreach \dest in {1,3,5}
		\draw[-stealth, thick] (dh1\source) -- (dh2\dest);

		\foreach \source in {1,3,5}
		\foreach \dest in {1,2}
		\draw[-stealth, thick] (dh2\source) -- (do\dest);

	\end{tikzpicture}
\end{center}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{../results/feature_importance.png}
	\caption{Feature Importance in Market Prediction Models}
	\label{fig:feature_importance}
\end{figure}

Model performance metrics showed the ensemble approach achieving 73\% accuracy in predicting next-day market states, with precision of 68\% for Bear markets and 76\% for Bull markets.

\section{Anomaly Detection System}
\subsection{Multi-method Anomaly Detection}
The anomaly detection system combines multiple algorithms to identify unusual market behavior:

\begin{enumerate}
	\item \textbf{Isolation Forest}: An unsupervised algorithm that isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of that feature. Anomalies require fewer splits to isolate, making them easy to identify.

	\item \textbf{DBSCAN Clustering}: Density-based approach that groups market days with similar characteristics and identifies days that don't belong to any cluster as anomalies.

	\item \textbf{Statistical Methods}: Z-score analysis of returns and volatility, identifying points beyond 3 standard deviations as potential anomalies.

	\item \textbf{Ensemble Anomaly Score}: A weighted combination of individual anomaly detection methods, which proved more reliable than any single method.
\end{enumerate}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{../results/anomalies/anomalies_visualization.png}
	\caption{Market Anomaly Detection Results}
	\label{fig:anomalies}
\end{figure}

\subsection{Catastrophe Modeling and Tail Risk Analysis}
We implemented advanced statistical techniques to model extreme market events:

\begin{itemize}
	\item \textbf{Extreme Value Theory}: Applied Generalized Pareto Distribution to model the tail of the return distribution, providing more accurate estimates of rare event probabilities.

	\item \textbf{Value at Risk (VaR) and Expected Shortfall (ES)}: Calculated at multiple confidence levels (95\%, 99\%, 99.9\%) using both historical and parametric methods.

	\item \textbf{Stress Testing}: Simulated extreme scenarios based on historical events (e.g., 2008 GFC, 2020 COVID crash) and analyzed portfolio response.
\end{itemize}

This analysis found that traditional risk measures significantly underestimate tail risk. For example, parametric VaR at 99\% confidence underestimated actual losses by approximately 40\% during crisis periods.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{../results/catastrophe/tail_risk_analysis.png}
	\caption{Tailed Risk Analysis}
	\label{fig:tailed_risk}
\end{figure}

\section{Investment Strategies}
\subsection{Strategy Framework}
We developed a systematic framework for investment strategies, ensuring consistent portfolio constraints:

\begin{itemize}
	\item Binary asset allocation between S\&P 500 Index and risk-free bonds
	\item No leverage allowed (maximum 100\% allocation to any asset)
	\item Daily rebalancing based on model predictions
	\item Strict risk management with dynamic position sizing
\end{itemize}

\subsection{Strategy Implementation}
We implemented and evaluated multiple strategies of increasing sophistication:

\begin{enumerate}
	\item \textbf{Buy-and-Hold}: Benchmark strategy with 100\% equity allocation

	\item \textbf{Prediction Strategy}: Binary allocation based solely on market state predictions

	\item \textbf{Dynamic Allocation}: Variable allocation based on prediction confidence

	\item \textbf{Combined Strategy}: Integration of predictions with technical indicators

	\item \textbf{Tactical Risk-Managed Strategy}: Maintains target volatility through dynamic allocation

	\item \textbf{Regime-Adaptive Strategy}: Adjusts allocations based on identified market regimes

	\item \textbf{Combined Anomaly-Regime Strategy}: Our most sophisticated approach, integrating anomaly detection with regime-based allocation
\end{enumerate}

The Combined Anomaly-Regime Strategy incorporates:
\begin{itemize}
	\item Real-time market regime identification
	\item Early warning system from the anomaly detector
	\item Adaptive allocation based on prediction confidence
	\item Volatility targeting with dynamic scaling
	\item Multi-timeframe trend analysis
	\item Yield curve analysis for macroeconomic context
\end{itemize}

\subsection{Strategy Optimization}
We optimized strategy parameters using:
\begin{itemize}
	\item Grid search over parameter spaces
	\item Walk-forward optimization to minimize overfitting
	\item Monte Carlo simulation to assess robustness
\end{itemize}

Key optimized parameters for the Combined Anomaly-Regime Strategy included:
\begin{itemize}
	\item Anomaly exit days: 10
	\item Normal bull allocation: 95\%
	\item Normal bear allocation: 15\%
	\item Regime smoothing factor: 5
	\item Recovery allocation: 60\%
\end{itemize}

\section{Performance Analysis and Results}

\subsection{Overall Performance Metrics}
The performance metrics for key strategies are summarized in Table \ref{performance}.

\begin{table}[htbp]
	\centering
	\begin{tabular}{l r r r r r}
		\toprule
		\textbf{Metric} & \textbf{Buy \& Hold} & \textbf{Prediction} & \textbf{Dynamic} & \textbf{Combined} & \textbf{Anomaly}  \\
		\midrule
		Total Return    & 52.97\%              & 44.89\%             & 53.49\%          & 41.77\%           & \textbf{56.41\%}  \\
		Annual Return   & 11.21\%              & 9.71\%              & 11.31\%          & 9.12\%            & \textbf{11.83\%}  \\
		Sharpe Ratio    & 0.58                 & 0.89                & 0.93             & 1.00              & \textbf{1.10}     \\
		Max Drawdown    & -33.92\%             & -13.89\%            & -13.62\%         & -11.70\%          & \textbf{-10.68\%} \\
		Win Rate        & 54.12\%              & 54.76\%             & 58.13\%          & 58.13\%           & \textbf{59.03\%}  \\
		\bottomrule
	\end{tabular}
	\caption{Performance Metrics for Trading Strategies (2019-2022)}
	\label{performance}
\end{table}

\subsection{Performance During Market Stress}
The strategies showed particularly notable differences during periods of market stress:

\begin{itemize}
	\item During the COVID-19 crash (March 2020), the Buy-and-Hold strategy experienced a -33.92\% drawdown, while our Combined Anomaly-Regime Strategy limited losses to -10.68\%.

	\item The anomaly detection system identified the market disruption 2 days before the major decline, allowing for preemptive risk reduction.

	\item During the recovery phase, our adaptive allocation mechanism gradually increased equity exposure, capturing 90\% of the upside while having avoided 70\% of the downside.
\end{itemize}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{../results/regime_allocations.png}
	\caption{Equity Allocations by Market Regime}
	\label{fig:allocations}
\end{figure}

\section{Conclusion and Future Work}

\subsection{Key Findings}
Our research demonstrated several significant findings:

\begin{enumerate}
	\item Machine learning models can effectively predict market states with accuracy significantly above random chance
	\item Ensemble approaches combining multiple model types and detection methods provide more robust performance
	\item The integration of anomaly detection with market state prediction substantially improves risk-adjusted returns
	\item Advanced deep learning techniques like attention mechanisms and TCNs capture market patterns that traditional models miss
	\item Dynamic, adaptive strategies significantly outperform static approaches on risk-adjusted metrics
\end{enumerate}

\subsection{Limitations}
We acknowledge several limitations in our approach:

\begin{itemize}
	\item Limited testing period (2019-2022) may not represent all market regimes
	\item Transaction costs and slippage were not incorporated in the backtest
	\item Binary asset allocation restriction limits potential diversification benefits
	\item Model training requires substantial historical data that may not be available for all markets
\end{itemize}

\subsection{Future Work}
Future research directions include:

\begin{itemize}
	\item Incorporating alternative data sources such as news sentiment and macroeconomic indicators
	\item Extending the asset universe to include multiple asset classes for greater diversification
	\item Implementing reinforcement learning for dynamic strategy optimization
	\item Developing more sophisticated risk parity approaches to balance risk contributions
	\item Exploring transfer learning to apply models across different markets and time periods
\end{itemize}

Our findings demonstrate that sophisticated machine learning approaches can significantly enhance investment decision-making, particularly for risk management during market stress periods. The combination of predictive modeling with anomaly detection provides a powerful framework for robust portfolio management in uncertain market environments.

\bibliographystyle{unsrt}
\bibliography{main}

\end{document}